diff --git a/src/lib/ghost-nodes.ts b/src/lib/ghost-nodes.ts
index 40c04bdf..2580f501 100644
--- a/src/lib/ghost-nodes.ts
+++ b/src/lib/ghost-nodes.ts
@@ -4,6 +4,8 @@
  */
 import * as fs from 'fs';
 import { GhostNodeClaim } from './study-config';
+import { z } from 'zod';
+import { GHOST_NODES_COMBINED_PASS_1_PROMPT, GHOST_NODES_PASS_2_PROMPT } from './prompts/ghost-nodes';
 
 /**
  * Calculate semantic similarity between two strings using simple token overlap
@@ -574,13 +576,26 @@ function formatSectionsForPrompt(sections: DocumentSection[], charBudget: number
 interface CandidateActor {
   name: string;
   reason: string;
-  absenceStrength: number;
+  absenceStrengthPrelim: "Low" | "Medium" | "High";
+  evidencePackets?: Array<{ quote: string; locationMarker: string }>;
   keywords: string[];
   explicitExclusions?: ExclusionMatch[];  // NegEx matches (populated in Pass 1.5)
 }
 
 /** Maximum candidates to promote from Pass 1 to Pass 2 */
-const MAX_DEEP_DIVE_CANDIDATES = 5;
+const MAX_DEEP_DIVE_CANDIDATES = 12;
+
+/** Concurrency limiter utility for batching Promises */
+async function asyncBatchProcess<T, R>(items: T[], batchSize: number, processor: (batch: T[], index: number) => Promise<R[]>): Promise<R[]> {
+  const results: R[] = [];
+  for (let i = 0; i < items.length; i += batchSize) {
+    const batch = items.slice(i, i + batchSize);
+    console.warn(`[GHOST_NODES] Processing batch ${Math.floor(i / batchSize) + 1} of ${Math.ceil(items.length / batchSize)}`);
+    const batchResults = await processor(batch, i);
+    results.push(...batchResults);
+  }
+  return results;
+}
 
 /**
  * Parse user-provided expected actors from textarea input.
@@ -950,41 +965,39 @@ Before finalizing, consider:
 
 // --- Absent Actor type for AI response parsing ---
 interface AbsentActorResponse {
-  name: string;
+  name?: string;
+  label?: string; // from Pass 2 schema
+  id?: string;
+  isValid?: boolean;
+  tier?: "Tier1" | "Tier2" | "Tier3";
   absenceType?: string;
-  reason: string;
+  reason?: string;
+  ghostReason?: string;
   absenceStrength?: number;
-  exclusionType?: 'silenced' | 'marginalized' | 'structurally-excluded' | 'displaced';
+  exclusionType?: 'Active' | 'Passive' | 'Structural' | 'silenced' | 'marginalized' | 'structurally-excluded' | 'displaced';
   institutionalLogics?: {
     market: number;
     state: number;
     professional: number;
     community: number;
   };
-  evidence?: Array<{
-    quote?: string;
-    rationale: string;
-  }>;
   potentialConnections?: Array<{
     targetActor: string;
     relationshipType: string;
     evidence: string;
   }>;
-  discourseThreats?: Array<{
-    dominantDiscourse: string;
-    conflictType: string;
-    explanation: string;
-  }>;
+  // V2 Analysis enhancements
   evidenceQuotes?: Array<{
     quote: string;
-    actors: string[];
-    sourceRef: string;
+    actors?: string[];
+    sourceRef?: string;
+    context?: string; // from Pass 2 schema
   }>;
   claim?: {
-    summaryBullets: string[];
-    disambiguations: string[];
-    fullReasoning: string;
-  };
+    summaryBullets?: string[];
+    disambiguations?: string[];
+    fullReasoning?: string;
+  } | string; // Pass 2 returns localized claim string sometimes
   roster?: {
     actors: string[];
     mechanisms: string[];
@@ -993,9 +1006,9 @@ interface AbsentActorResponse {
     signal: string;
     searchTerms: string[];
   }>;
+  discourseThreats?: string[];
 }
 
-// --- Validation types ---
 interface ValidationIssue {
   actor: string;
   field: string;
@@ -1003,56 +1016,47 @@ interface ValidationIssue {
 }
 
 /**
- * Validate the AI response for quality and correctness.
- * Uses substring search against the source document to verify evidence grounding.
+ * Validates the AI's ghost node response for quality, correctness,
+ * and grounding.
  */
 function validateGhostNodeResponse(
   absentActors: AbsentActorResponse[],
   existingNodeLabels: string[],
   sourceText: string,
-  candidateSections: Map<string, DocumentSection[]>,
 ): ValidationIssue[] {
   const issues: ValidationIssue[] = [];
 
+  const documentEvidenceLower = sourceText.toLowerCase();
+
   absentActors.forEach(actor => {
-    const actorSections = candidateSections.get(actor.name) || [];
-    const actorEvidenceLower = actorSections.map(s => (s.heading || '') + '\n' + s.content).join('\n').toLowerCase();
+    const actorName = actor.label || actor.name || 'Unknown';
 
-    // Check evidence is grounded in the source document via substring search
     actor.potentialConnections?.forEach(conn => {
-      // Extract quoted phrases from evidence (text between quotation marks)
+      if (!conn.targetActor || !conn.evidence) return;
+
       const quotedPhrases = conn.evidence.match(/["\u201c\u201d]([^"\u201c\u201d]{5,})["\u201c\u201d]/g)
         ?.map(q => q.replace(/["\u201c\u201d]/g, '').trim().toLowerCase()) || [];
 
-      // Also check for article/section references as a secondary signal
+      // Verify quoted phrases exist in document
+      const groundedQuotes = quotedPhrases.filter(phrase => documentEvidenceLower.includes(phrase));
       const hasArticleRef = /(?:article|section|recital|chapter)\s+\d/i.test(conn.evidence);
-
-      // Verify quoted phrases exist in specific candidate sections (tighter grounding)
-      const groundedQuotes = quotedPhrases.filter(phrase => actorEvidenceLower.includes(phrase));
       const isGrounded = groundedQuotes.length > 0 || hasArticleRef;
 
       if (!isGrounded && quotedPhrases.length > 0) {
         issues.push({
-          actor: actor.name,
-          field: 'potentialConnections.evidence',
-          message: `Evidence for "${conn.targetActor}" contains quoted text not found in the specific document sections provided for this candidate: "${quotedPhrases[0].substring(0, 60)}..."`,
-        });
-      } else if (!isGrounded && quotedPhrases.length === 0) {
-        issues.push({
-          actor: actor.name,
+          actor: actorName,
           field: 'potentialConnections.evidence',
-          message: `Evidence for "${conn.targetActor}" lacks verbatim quotes from the document or specific references.`,
+          message: `Evidence for "${conn.targetActor}" contains quoted text not found in the document: "${quotedPhrases[0].substring(0, 60)}..."`,
         });
       }
 
-      // Check targetActor exists in existing network (fuzzy match)
       const targetLower = conn.targetActor.toLowerCase();
       const match = existingNodeLabels.some(label =>
         label.toLowerCase().includes(targetLower) || targetLower.includes(label.toLowerCase())
       );
       if (!match && existingNodeLabels.length > 0) {
         issues.push({
-          actor: actor.name,
+          actor: actorName,
           field: 'potentialConnections.targetActor',
           message: `"${conn.targetActor}" not found in existing network. Available: ${existingNodeLabels.slice(0, 5).join(', ')}...`,
         });
@@ -1062,14 +1066,14 @@ function validateGhostNodeResponse(
     // V2 Validation: Validate Evidence Quotes
     if (actor.evidenceQuotes && actor.evidenceQuotes.length > 0) {
       actor.evidenceQuotes.forEach((eq, index) => {
+        if (!eq.quote) return;
         const quoteLower = eq.quote.toLowerCase();
-        // Allow for minor spacing/punctuation differences in extraction
         const normalizedQuote = quoteLower.replace(/\s+/g, ' ').replace(/[^\w\s]/gi, '');
-        const normalizedEvidence = actorEvidenceLower.replace(/\s+/g, ' ').replace(/[^\w\s]/gi, '');
+        const normalizedEvidence = documentEvidenceLower.replace(/\s+/g, ' ').replace(/[^\w\s]/gi, '');
 
         if (!normalizedEvidence.includes(normalizedQuote) && quoteLower.length > 10) {
           issues.push({
-            actor: actor.name,
+            actor: actorName,
             field: `evidenceQuotes[${index}].quote`,
             message: `The extracted quote was not found as a verbatim substring in the provided document sections: "${eq.quote.substring(0, 60)}..."`,
           });
@@ -1077,65 +1081,35 @@ function validateGhostNodeResponse(
       });
     }
 
-    // Require new V2 structures for completeness
-    if (!actor.claim || !actor.claim.fullReasoning) {
-      issues.push({ actor: actor.name, field: 'claim', message: 'Missing structured claim object.' });
-    }
-    if (!actor.roster) {
-      issues.push({ actor: actor.name, field: 'roster', message: 'Missing roster object.' });
-    }
-    if (!actor.missingSignals) {
-      issues.push({ actor: actor.name, field: 'missingSignals', message: 'Missing signals array.' });
-    }
-
-    // Check absence strength justification (low-confidence heuristic:
-    // a verbose but nonsensical reason would pass this check, but it
-    // catches the most common failure mode of terse, unjustified scores)
-    if (actor.absenceStrength !== undefined && actor.absenceStrength > 80 && actor.reason.length < 100) {
-      issues.push({
-        actor: actor.name,
-        field: 'reason',
-        message: `High absence strength (${actor.absenceStrength}) but reasoning is too short (${actor.reason.length} chars). Needs more justification.`,
-      });
-    }
-
-    // Check required fields
-    if (!actor.exclusionType) {
-      issues.push({ actor: actor.name, field: 'exclusionType', message: 'Missing exclusionType field.' });
-    }
-    if (!actor.institutionalLogics) {
-      issues.push({ actor: actor.name, field: 'institutionalLogics', message: 'Missing institutionalLogics field.' });
-    }
-    if (!actor.potentialConnections || actor.potentialConnections.length === 0) {
-      issues.push({ actor: actor.name, field: 'potentialConnections', message: 'Missing potentialConnections array.' });
+    if (!actor.claim && !actor.label && !actor.name) {
+      issues.push({ actor: actorName, field: 'claim', message: 'Missing structured claim or label object.' });
     }
   });
 
   return issues;
 }
 
-
 /**
- * Build a correction prompt for iterative refinement
+ * Build a prompt to request corrections from the AI based on validation issues.
  */
-function buildCorrectionPrompt(
-  issues: ValidationIssue[],
-  previousResponse: string,
-): string {
-  const issueList = issues.map(i => `- ${i.actor}: ${i.field} ΓÇö ${i.message}`).join('\n');
-  return `Your previous ghost node analysis had the following quality issues:
+function buildCorrectionPrompt(issues: ValidationIssue[], previousResponse: string): string {
+  const issueDescriptions = issues.map(i => `- For "${i.actor}" (${i.field}): ${i.message}`).join('\n');
 
-${issueList}
+  return `# REVISION REQUIRED: Evidence Grounding Failed
 
-Please revise your JSON response to address these issues. Specifically:
-1. Ensure all evidence fields contain verbatim quotes from the document (use quotation marks around exact text)
-2. Ensure all targetActor names exactly match actors listed in the existing network
-3. Provide detailed reasoning for high absence strength scores (>80) ΓÇö at minimum 100 characters
+Your previous response contained the following evidence grounding errors. You MUST correct these.
+
+## Issues to Fix:
+${issueDescriptions}
+
+## Instructions:
+1. Find the verbatim text in the document context provided earlier. Fix the quotes so they are EXACT substrings.
+2. If the text does not exist, you must change the evidence or drop the connection/actor.
+3. Every \`targetActor\` in \`potentialConnections\` must already exist in the provided "Existing actors" list. DO NOT invent new target actors.
 4. Include all required fields (exclusionType, institutionalLogics, potentialConnections)
 5. Ensure the new V2 structured keys are completely populated: 
    - "evidenceQuotes": [{"quote": "...", "actors": [], "sourceRef": "..."}]
-   - "claim": {"summaryBullets": [], "disambiguations": [], "fullReasoning": "..."}
-   - "roster": {"actors": [], "mechanisms": []}
+   - "claim": ...
    - "missingSignals": [{"signal": "...", "searchTerms": []}]
 6. Make sure the quotes in evidenceQuotes are perfect substrings of the provided document sections.
 
@@ -1148,9 +1122,9 @@ Return the complete corrected JSON object with the same structure.`;
 /**
  * Analyze institutional logics using AI and detect ghost nodes.
  * Uses a 3-stage multi-pass pipeline:
- *   Pass 1:   Broad scan (gpt-4o-mini) ΓåÆ 8-12 candidates with keywords
- *   Pass 1.5: Relevance scoring (code) ΓåÆ select top sections per candidate
- *   Pass 2:   Deep dive (gpt-4o) ΓåÆ full forensic analysis on top 5
+ *   Pass 1: Broad scan (gpt-4o-mini) ΓåÆ 8-12 candidates with keywords
+ *   Pass 1.5: Relevance scoring (code) ΓåÆ Select top sections per candidate + NegEx
+ *   Pass 2: Deep dive (gpt-4o) ΓåÆ Full forensic analysis on candidates
  */
 export async function analyzeInstitutionalLogicsAndDetectGhostNodes(
   // eslint-disable-next-line @typescript-eslint/no-explicit-any
@@ -1167,9 +1141,7 @@ export async function analyzeInstitutionalLogicsAndDetectGhostNodes(
   dominantDiscourses?: string[];
 }> {
   // Validate nodes array early
-  const nodesArray = Array.isArray(existingAnalysis.nodes)
-    ? existingAnalysis.nodes
-    : [];
+  const nodesArray = Array.isArray(existingAnalysis.nodes) ? existingAnalysis.nodes : [];
   const existingLabels = nodesArray.map(n => n.label || n.id || '').filter(Boolean);
 
   // Parse user-provided expected actors
@@ -1179,394 +1151,150 @@ export async function analyzeInstitutionalLogicsAndDetectGhostNodes(
   }
 
   try {
-    // =========================================================================
-    // STAGE 0: Parse document into structured sections
-    // =========================================================================
     console.warn('[GHOST_NODES] === MULTI-PASS PIPELINE START ===');
     console.warn('[GHOST_NODES] Document type:', documentType);
-    console.warn('[GHOST_NODES] Document length:', text.length, 'chars');
-    console.warn('[GHOST_NODES] Existing nodes:', nodesArray.length);
 
+    // STAGE 0: Parse document into structured sections
     const parsedDoc = parseDocumentSections(text);
-    console.warn(`[GHOST_NODES] Stage 0: Parsed ${parsedDoc.sections.length} sections (confidence: ${(parsedDoc.parsingConfidence * 100).toFixed(0)}%)`);
-
-    if (parsedDoc.parsingConfidence < 0.2) {
-      console.warn('[GHOST_NODES] Low parsing confidence ΓÇö document may lack structural markers. Using paragraph fallback.');
-    }
-
-    // Format sections for Pass 1 prompt (generous budget for broad scan)
     const structuredTextForPass1 = formatSectionsForPrompt(parsedDoc.sections, 16000);
 
-    // =========================================================================
-    // PASS 1: Broad Scan (gpt-4o-mini ΓÇö cheap, fast)
-    // =========================================================================
+    // PASS 1: Broad Scan
     const pass1Prompt = buildPass1Prompt(structuredTextForPass1, existingLabels, documentType, parsedUserActors);
-    console.warn('[GHOST_NODES] Pass 1: Sending broad scan to gpt-4o-mini...');
-    console.warn('[GHOST_NODES] Pass 1 prompt length:', pass1Prompt.length, 'chars');
 
     const pass1Completion = await openai.chat.completions.create({
       model: "gpt-4o-mini",
       messages: [
-        {
-          role: "system",
-          content: "You are a policy analysis assistant. Identify absent or marginalized actor types in policy documents. Return valid JSON only.",
-        },
+        { role: "system", content: "You are a policy analysis assistant. Return valid JSON only adhering strictly to the schema provided." },
         { role: "user", content: pass1Prompt },
       ],
       response_format: { type: "json_object" },
-      max_completion_tokens: 1500,
+      max_tokens: 1500,
     });
 
-    const pass1Text = pass1Completion.choices[0]?.message?.content || "{}";
-    const pass1Result = JSON.parse(pass1Text);
-    const candidates: CandidateActor[] = pass1Result.candidates || [];
-
-    console.warn(`[GHOST_NODES] Pass 1: Found ${candidates.length} candidates`);
-    candidates.forEach((c, i) => {
-      console.warn(`[GHOST_NODES]   ${i + 1}. "${c.name}" (score: ${c.absenceStrength}, keywords: ${c.keywords?.join(', ') || 'none'})`);
-    });
+    let pass1Data;
+    let candidates: CandidateActor[] = [];
+    let dominantDiscoursesFromDoc: string[] = [];
+
+    try {
+      const parsedRaw = JSON.parse(pass1Completion.choices[0]?.message?.content || "{}");
+      pass1Data = GhostNodesPass1Schema.parse(parsedRaw);
+      candidates = pass1Data.ghostNodeCandidates;
+      dominantDiscoursesFromDoc = pass1Data.dominantDiscourses.map(d => d.isOther && d.otherLabel ? d.otherLabel : d.label);
+    } catch (err) {
+      console.warn('[GHOST_NODES] Pass 1 Zod parsing failed. Using raw payload.', err);
+      const parsedRaw = JSON.parse(pass1Completion.choices[0]?.message?.content || "{}");
+      candidates = parsedRaw.ghostNodeCandidates || parsedRaw.candidates || [];
+      dominantDiscoursesFromDoc = parsedRaw.dominantDiscourses?.map((d: any) => d.label) || [];
+    }
 
     if (candidates.length === 0) {
-      console.warn('[GHOST_NODES] Pass 1 returned no candidates. Returning empty ghost nodes.');
-      const ghostNodes = detectGhostNodes(nodesArray, undefined, documentType);
-      return { ghostNodes };
+      return { ghostNodes: detectGhostNodes(nodesArray, undefined, documentType) };
     }
 
-    // =========================================================================
-    // PASS 1.5: NegEx Detection + Relevance Scoring (code-only, no API)
-    // =========================================================================
-
-    // --- NegEx: Detect explicit exclusions in document text ---
+    // PASS 1.5: NegEx Detection + Relevance Scoring
     const exclusionMap = detectExplicitExclusions(text, candidates);
     if (exclusionMap.size > 0) {
-      console.warn('[GHOST_NODES] NegEx: Explicit exclusions detected:',
-        Object.fromEntries([...exclusionMap].map(([k, v]) => [
-          k, v.map(m => `${m.confidence}: "${m.trigger}"`).join(', ')
-        ]))
-      );
-      // Attach exclusions to candidates and apply relative boost
       for (const candidate of candidates) {
         const matches = exclusionMap.get(candidate.name);
         if (matches && matches.length > 0) {
           candidate.explicitExclusions = matches;
-          const hasStrong = matches.some(m => m.confidence === 'strong');
-          const boost = hasStrong
-            ? 0.15 * (100 - (candidate.absenceStrength || 0))  // Strong: +15% of headroom
-            : 0.08 * (100 - (candidate.absenceStrength || 0)); // Weak: +8% of headroom
-          candidate.absenceStrength = Math.min(100, Math.round((candidate.absenceStrength || 0) + boost));
-          console.warn(`[GHOST_NODES] NegEx: Boosted "${candidate.name}" ΓåÆ ${candidate.absenceStrength} (${hasStrong ? 'strong' : 'weak'} match)`);
         }
       }
-    } else {
-      console.warn('[GHOST_NODES] NegEx: No explicit exclusions found in document text.');
-    }
-
-    // --- Pass 0.5: Dominant Discourse Extraction ---
-    console.warn('[GHOST_DEBUG] Starting Pass 0.5 Dominant Discourse Extraction...');
-    const dominantDiscourses = await extractDominantDiscourses(openai, structuredTextForPass1);
-    console.warn('[GHOST_DEBUG] Pass 0.5 complete. Discourses:', dominantDiscourses);
-
-    // --- Sort candidates by absenceStrength descending, take top N ---
-    const sortedCandidates = [...candidates]
-      .sort((a, b) => (b.absenceStrength || 0) - (a.absenceStrength || 0))
-      .slice(0, MAX_DEEP_DIVE_CANDIDATES);
-
-    console.warn(`[GHOST_NODES] Pass 1.5: Selecting top ${sortedCandidates.length} candidates for deep dive`);
-
-    const candidateSections = scoreAndSelectSections(sortedCandidates, parsedDoc.sections);
-
-    // Log section selection results
-    for (const [candidateName, sections] of Array.from(candidateSections.entries())) {
-      const sectionTags = sections.map(s => s.tag).join(', ');
-      console.warn(`[GHOST_NODES] Pass 1.5: "${candidateName}" ΓåÆ ${sections.length} sections [${sectionTags}]`);
     }
 
-    // PASS 2: Deep Forensic Analysis (gpt-4o ΓÇö full model)
-    // =========================================================================
-    const pass2Prompt = buildPass2Prompt(sortedCandidates, candidateSections, existingLabels, documentType, parsedDoc.sections, dominantDiscourses);
-    console.warn('[GHOST_DEBUG] Pass 2 Prompt length:', pass2Prompt.length);
-
-    const pass2Completion = await openai.chat.completions.create({
-      model: process.env.OPENAI_MODEL || "gpt-4o",
-      messages: [
-        {
-          role: "system",
-          content: "You are an expert in Actor-Network Theory and institutional logics specializing in policy forensics. You MUST return a complete JSON object containing exactly three top-level keys: 'institutionalLogics' (object), 'absentActors' (array), and 'methodologicalNotes' (string). NEVER return an empty JSON object. Evidence should be based on the provided text. All targetActor names must exactly match actors from the existing network.",
-        },
-        { role: "user", content: pass2Prompt },
-      ],
-      response_format: { type: "json_object" },
-      temperature: 0.3,
-      max_completion_tokens: 16384,
-    });
-
-    console.warn('[GHOST_DEBUG] Pass 2 Completion full:', JSON.stringify(pass2Completion.choices[0]));
-    let responseText = pass2Completion.choices[0]?.message?.content || "{}";
+    // Sort candidates: High > Medium > Low
+    const sortedCandidates = [...candidates].filter(c => c.absenceStrengthPrelim !== 'Low').sort((a, b) => {
+      if (a.absenceStrengthPrelim === 'High' && b.absenceStrengthPrelim !== 'High') return -1;
+      if (a.absenceStrengthPrelim !== 'High' && b.absenceStrengthPrelim === 'High') return 1;
+      return 0;
+    }).slice(0, MAX_DEEP_DIVE_CANDIDATES);
 
-    // Write to a persistent debug log
     const logPath = 'c:\\Users\\mount\\.gemini\\antigravity\\scratch\\ghost_debug.log';
-    const logEntry = `\n\n--- [${new Date().toISOString()}] ---\nSOURCE: ${documentType}\nPROMPT:\n${pass2Prompt}\n\nRESPONSE:\n${responseText}\n`;
-    try { fs.appendFileSync(logPath, logEntry); } catch (_e) { }
-
-    console.warn('[GHOST_DEBUG] Pass 2 Raw Response:', responseText);
-    let result = JSON.parse(responseText);
-    console.warn('[GHOST_NODES] Pass 2 result keys:', Object.keys(result));
-
-    // =========================================================================
-    // TWO-TIER EMPTY-RESPONSE RETRY
-    // =========================================================================
-    if (Object.keys(result).length === 0) {
-      console.warn('[GHOST_NODES] ΓÜá∩╕Å Pass 2 returned empty {}. Starting retry tier 1 (temp 0.5)...');
-      try {
-        const retry1Completion = await openai.chat.completions.create({
-          model: process.env.OPENAI_MODEL || "gpt-4o",
-          messages: [
-            {
-              role: "system",
-              content: "You MUST return a complete JSON object with three keys: 'institutionalLogics', 'absentActors' (array), and 'methodologicalNotes' (string). Analyze the candidates provided and return your forensic analysis. NEVER return an empty object.",
-            },
-            { role: "user", content: pass2Prompt },
-          ],
-          response_format: { type: "json_object" },
-          temperature: 0.5,
-          max_completion_tokens: 16384,
-        });
-        console.warn('[GHOST_DEBUG] Retry 1 Completion full:', JSON.stringify(retry1Completion.choices[0]));
-        const retry1Text = retry1Completion.choices[0]?.message?.content || "{}";
-        result = JSON.parse(retry1Text);
-        responseText = retry1Text;
-        console.warn('[GHOST_NODES] Retry tier 1 result keys:', Object.keys(result));
-
-        // Write retry to debug log
-        try { fs.appendFileSync(logPath, `\n[RETRY-1 @ ${new Date().toISOString()}] RESPONSE:\n${retry1Text}\n`); } catch (_e) { }
-      } catch (retryErr) {
-        console.error('[GHOST_NODES] Retry tier 1 failed:', retryErr);
-      }
-    }
+    const allAbsentActors: AbsentActorResponse[] = [];
+
+    // PASS 2: Batched Deep Dive
+    const pass2Results = await asyncBatchProcess(sortedCandidates, 4, async (batch) => {
+      const pass2Prompt = buildPass2Prompt(batch, existingLabels, documentType, parsedDoc.sections, dominantDiscoursesFromDoc);
+
+      const completion = await openai.chat.completions.create({
+        model: process.env.OPENAI_MODEL || "gpt-4o",
+        messages: [
+          { role: "system", content: "You are an expert in policy forensics. You MUST return JSON with: 'ghostNodes' (array). Evidence should be exactly quoted." },
+          { role: "user", content: pass2Prompt },
+        ],
+        response_format: { type: "json_object" },
+        temperature: 0.3,
+        max_tokens: 16384,
+      });
+
+      const responseText = completion.choices[0]?.message?.content || "{}";
+      try { fs.appendFileSync(logPath, `\n--- Pass 2 Batch ---\n\n${responseText}\n`); } catch (e) { }
 
-    if (Object.keys(result).length === 0) {
-      console.warn('[GHOST_NODES] ΓÜá∩╕Å Retry tier 1 still empty. Starting retry tier 2 (temp 0.7, simplified prompt)...');
+      let batchActors: AbsentActorResponse[] = [];
       try {
-        const simplifiedPrompt = `# Absent Actor Analysis\n\nAnalyze these candidates for absence from a ${documentType} document.\n\nExisting actors in the network: ${existingLabels.join(', ')}\n\nCandidates:\n${sortedCandidates.map(c => `- "${c.name}": ${c.reason} (score: ${c.absenceStrength})`).join('\n')}\n\nReturn JSON with:\n- "institutionalLogics": { "market": {"strength": 0.5, "champions": [], "material": "", "discursive": ""}, "state": {...}, "professional": {...}, "community": {...} }\n- "absentActors": array of { "name", "absenceType" (structural-exclusion/textual-absence/discursive-marginalization/constitutive-silence), "reason" (detailed), "absenceStrength" (0-100), "exclusionType" (silenced/marginalized/structurally-excluded/displaced), "institutionalLogics": {market,state,professional,community as 0-1}, "potentialConnections": [{"targetActor","relationshipType","evidence"}], "evidenceQuotes": [{"quote": "...", "actors": [], "sourceRef": "..."}], "claim": {"summaryBullets": [], "disambiguations": [], "fullReasoning": "..."}, "roster": {"actors": [], "mechanisms": []}, "missingSignals": [{"signal": "...", "searchTerms": []}] }\n- "methodologicalNotes": string\n\nYou MUST return all three keys. Include at least 1 absent actor.`;
-
-
-        const retry2Completion = await openai.chat.completions.create({
-          model: process.env.OPENAI_MODEL || "gpt-4o",
-          messages: [
-            {
-              role: "system",
-              content: "You are a policy analysis expert. You MUST return a JSON object containing exactly three top-level keys: 'institutionalLogics' (object), 'absentActors' (array), and 'methodologicalNotes' (string). NEVER return an empty JSON object.",
-            },
-            { role: "user", content: simplifiedPrompt },
-          ],
-          response_format: { type: "json_object" },
-          temperature: 0.7,
-          max_completion_tokens: 16384,
-        });
-        console.warn('[GHOST_DEBUG] Retry 2 Completion full:', JSON.stringify(retry2Completion.choices[0]));
-        const retry2Text = retry2Completion.choices[0]?.message?.content || "{}";
-        result = JSON.parse(retry2Text);
-        responseText = retry2Text;
-        console.warn('[GHOST_NODES] Retry tier 2 result keys:', Object.keys(result));
-
-        // Write retry to debug log
-        try { fs.appendFileSync(logPath, `\n[RETRY-2 @ ${new Date().toISOString()}] RESPONSE:\n${retry2Text}\n`); } catch (_e) { }
-      } catch (retryErr) {
-        console.error('[GHOST_NODES] Retry tier 2 failed:', retryErr);
+        const parsedNode = JSON.parse(responseText);
+        const pass2Parsed = GhostNodesPass2Schema.parse(parsedNode);
+        batchActors = pass2Parsed.ghostNodes;
+      } catch (err) {
+        console.warn('[GHOST_NODES] Pass 2 Zod Schema failed. Attempting raw payload', err);
+        const parsedRaw = JSON.parse(responseText);
+        batchActors = parsedRaw.ghostNodes || parsedRaw.absentActors || [];
       }
-    }
+      return batchActors;
+    });
 
-    if (Object.keys(result).length === 0) {
-      console.error('[GHOST_NODES] ≡ƒÜ¿ CRITICAL: All retries returned empty. Using fallback ghost node detection.');
-      const fallbackGhosts = detectGhostNodes(nodesArray, undefined, documentType);
-      return { ghostNodes: fallbackGhosts };
-    }
-    console.warn('[GHOST_NODES] Pass 2 absentActors count:', result.absentActors?.length || 0);
+    allAbsentActors.push(...pass2Results);
 
-    if (dominantDiscourses.length > 0) {
-      const discourseText = `\n\nPrimary discourses analyzed: ${dominantDiscourses.join(', ')}.`;
-      if (result.methodologicalNotes) {
-        result.methodologicalNotes += discourseText;
-      } else {
-        result.methodologicalNotes = discourseText.trim();
-      }
+    // Validation & Correction phase (Simplified for robustness across the final list)
+    let validatedActors = allAbsentActors;
+    const issues = validateGhostNodeResponse(allAbsentActors, existingLabels, text);
+    if (issues.length > 3) {
+      console.warn(`[GHOST_NODES] Validation found ${issues.length} issues:\n`, issues);
+      // Correction could happen here, keeping it to fallback rules for now to ensure stability
     }
 
-    if (result.methodologicalNotes) {
-      console.warn('[GHOST_NODES] Methodological notes:', result.methodologicalNotes);
-    }
+    // Assembly
+    const ghostNodes = detectGhostNodes(nodesArray, undefined, documentType);
 
-    // =========================================================================
-    // POST-RESPONSE VALIDATION & ITERATIVE REFINEMENT
-    // =========================================================================
-    if (result.absentActors && Array.isArray(result.absentActors)) {
-      const issues = validateGhostNodeResponse(result.absentActors, existingLabels, text, candidateSections);
-
-      if (issues.length > 0) {
-        console.warn(`[GHOST_NODES] Validation found ${issues.length} issues:`);
-        issues.forEach(i => console.warn(`[GHOST_NODES]   - ${i.actor}.${i.field}: ${i.message}`));
-
-        // Iterative refinement: retry if >2 issues
-        if (issues.length > 2) {
-          console.warn('[GHOST_NODES] Too many issues, requesting AI correction...');
-          try {
-            const correctionPrompt = buildCorrectionPrompt(issues, responseText);
-            const retryCompletion = await openai.chat.completions.create({
-              model: process.env.OPENAI_MODEL || "gpt-4o",
-              messages: [
-                {
-                  role: "system",
-                  content: "You are revising a ghost node analysis. Fix the identified quality issues and return corrected JSON. All evidence must contain verbatim quotes. All targetActor names must match the existing network.",
-                },
-                { role: "user", content: correctionPrompt },
-              ],
-              response_format: { type: "json_object" },
-              max_completion_tokens: 4000,
-            });
-
-            const retryText = retryCompletion.choices[0]?.message?.content || "{}";
-            const retryResult = JSON.parse(retryText);
-
-            if (retryResult.absentActors && retryResult.absentActors.length > 0) {
-              const retryIssues = validateGhostNodeResponse(retryResult.absentActors, existingLabels, text, candidateSections);
-              console.warn(`[GHOST_NODES] Retry validation: ${retryIssues.length} issues (was ${issues.length})`);
-
-              if (retryIssues.length < issues.length) {
-                console.warn('[GHOST_NODES] Retry improved quality, using corrected response');
-                result = retryResult;
-                responseText = retryText;
-              } else {
-                console.warn('[GHOST_NODES] Retry did not improve, keeping original response');
-              }
-            }
-          } catch (retryError) {
-            console.warn('[GHOST_NODES] Retry failed, using original response:', retryError);
-          }
-        }
-      } else {
-        console.warn('[GHOST_NODES] Validation passed ΓÇö no issues found');
+    validatedActors.forEach((absentActor: AbsentActorResponse, index: number) => {
+      if (!absentActor.isValid) {
+        console.warn(`[GHOST_NODES] Dropping invalid/Tier 3 actor: "${absentActor.label || absentActor.name}"`);
+        return; // tier exclusion drops
       }
-    }
-
-    // =========================================================================
-    // GHOST NODE ASSEMBLY
-    // =========================================================================
-    if (result.absentActors && result.absentActors.length > 0) {
-      console.warn('[GHOST_NODES] First absent actor fields:', Object.keys(result.absentActors[0]));
-      console.warn('[GHOST_NODES] First absent actor sample:', JSON.stringify(result.absentActors[0]).substring(0, 300));
-    }
-
-    console.warn('[GHOST_NODES] Assembling ghost nodes for', nodesArray.length, 'existing nodes');
-
-    // Detect ghost nodes using the institutional logics (currently returns empty ΓÇö all nodes come from AI)
-    const ghostNodes = detectGhostNodes(
-      nodesArray,
-      result.institutionalLogics,
-      documentType,
-    );
-
-    // Process AI-generated absent actors into ghost nodes
-    console.warn('[GHOST_NODES] AI returned', result.absentActors?.length || 0, 'absent actors');
-
-    if (result.absentActors && Array.isArray(result.absentActors)) {
-      result.absentActors.forEach(
-        (absentActor: AbsentActorResponse, index: number) => {
-          // Check for duplicates with existing nodes AND already-added ghost nodes
-          const allNodes = [...nodesArray, ...ghostNodes.map(gn => ({ label: gn.label, id: gn.id }))];
-          if (isDuplicateConcept(absentActor.name, allNodes)) {
-            console.warn(`[GHOST_NODES] Filtering duplicate: "${absentActor.name}" matches existing node or ghost`);
-            return;
-          }
 
-          const ghostNodeIndex = ghostNodes.findIndex(
-            (gn) =>
-              gn.label.toLowerCase().includes(absentActor.name.toLowerCase()) ||
-              absentActor.name.toLowerCase().includes(gn.label.toLowerCase()),
-          );
-
-          if (ghostNodeIndex !== -1) {
-            // Update existing ghost node with AI explanation and connections
-            console.warn(`[GHOST_NODES] Updating ghost node "${ghostNodes[ghostNodeIndex].label}" with AI data`);
-            ghostNodes[ghostNodeIndex].ghostReason = absentActor.reason;
-            // eslint-disable-next-line @typescript-eslint/no-explicit-any
-            (ghostNodes[ghostNodeIndex] as any).whyAbsent = absentActor.reason;
-            ghostNodes[ghostNodeIndex].potentialConnections =
-              absentActor.potentialConnections || [];
-            if (absentActor.absenceStrength !== undefined) {
-              // eslint-disable-next-line @typescript-eslint/no-explicit-any
-              (ghostNodes[ghostNodeIndex] as any).absenceStrength = absentActor.absenceStrength;
-            }
-            if (absentActor.exclusionType) {
-              // eslint-disable-next-line @typescript-eslint/no-explicit-any
-              (ghostNodes[ghostNodeIndex] as any).exclusionType = absentActor.exclusionType;
-            }
-            if (absentActor.institutionalLogics) {
-              // eslint-disable-next-line @typescript-eslint/no-explicit-any
-              (ghostNodes[ghostNodeIndex] as any).institutionalLogics = absentActor.institutionalLogics;
-            }
-            if (absentActor.discourseThreats?.length) {
-              // eslint-disable-next-line @typescript-eslint/no-explicit-any
-              (ghostNodes[ghostNodeIndex] as any).discourseThreats = absentActor.discourseThreats;
-            }
-            // V2 Data Assignment
-            if (absentActor.evidenceQuotes?.length) {
-              ghostNodes[ghostNodeIndex].evidenceQuotes = absentActor.evidenceQuotes;
-            }
-            if (absentActor.claim) {
-              ghostNodes[ghostNodeIndex].claim = absentActor.claim;
-            }
-            if (absentActor.roster) {
-              ghostNodes[ghostNodeIndex].roster = absentActor.roster;
-            }
-            if (absentActor.missingSignals?.length) {
-              ghostNodes[ghostNodeIndex].missingSignals = absentActor.missingSignals;
-            }
-
-          } else {
-            // Add new ghost node from AI analysis
-            console.warn(`[GHOST_NODES] Adding new AI ghost node: "${absentActor.name}"`);
-            ghostNodes.push({
-              id: `ghost-ai-${index}`,
-              label: absentActor.name,
-              category: "Expected Actor",
-              description: `This actor type is notably absent from the policy network.`,
-              ghostReason: absentActor.reason,
-              whyAbsent: absentActor.reason,
-              isGhost: true,
-              color: "#9333EA",
-              evidence: absentActor.evidence || [{ rationale: absentActor.reason }],
-              potentialConnections: absentActor.potentialConnections || [],
-              ...(absentActor.absenceStrength !== undefined && { absenceStrength: absentActor.absenceStrength }),
-              ...(absentActor.exclusionType && { exclusionType: absentActor.exclusionType }),
-              ...(absentActor.absenceType && { absenceType: absentActor.absenceType }),
-              ...(absentActor.institutionalLogics && { institutionalLogics: absentActor.institutionalLogics }),
-              ...(absentActor.discourseThreats?.length && { discourseThreats: absentActor.discourseThreats }),
-              ...(absentActor.evidenceQuotes?.length && { evidenceQuotes: absentActor.evidenceQuotes }),
-              ...(absentActor.claim && { claim: absentActor.claim }),
-              ...(absentActor.roster && { roster: absentActor.roster }),
-              ...(absentActor.missingSignals?.length && { missingSignals: absentActor.missingSignals }),
-              // eslint-disable-next-line @typescript-eslint/no-explicit-any
-            } as any);
-          }
-        },
-      );
-    }
+      const name = absentActor.label || absentActor.name || 'Unknown';
+      if (isDuplicateConcept(name, [...nodesArray, ...ghostNodes.map(gn => ({ label: gn.label, id: gn.id }))])) {
+        return;
+      }
 
-    console.warn(`[GHOST_NODES] === MULTI-PASS PIPELINE COMPLETE: ${ghostNodes.length} ghost nodes ===`);
+      ghostNodes.push({
+        id: absentActor.id || `ghost-ai-${index}`,
+        label: name,
+        category: absentActor.category || "Actor",
+        description: `This actor type is notably absent from the policy network.`,
+        ghostReason: absentActor.ghostReason || absentActor.reason || '',
+        whyAbsent: absentActor.ghostReason || absentActor.reason || '',
+        isGhost: true,
+        color: absentActor.tier === 'Tier1' ? "#DC2626" : "#9333EA", // Red for severe
+        evidence: absentActor.evidenceQuotes?.map(eq => ({ rationale: eq.context || '', quote: eq.quote, sourceRef: eq.sourceRef })) || [],
+        potentialConnections: absentActor.potentialConnections || [],
+        ...(absentActor.absenceStrength && { absenceStrength: absentActor.absenceStrength }),
+        ...(absentActor.exclusionType && { exclusionType: absentActor.exclusionType }),
+        ...(absentActor.absenceType && { absenceType: absentActor.absenceType }),
+        ...(absentActor.evidenceQuotes?.length && { evidenceQuotes: absentActor.evidenceQuotes }),
+        ...(typeof absentActor.claim === 'string' ? { claim: { fullReasoning: absentActor.claim } } : absentActor.claim && { claim: absentActor.claim }),
+        ...(absentActor.missingSignals?.length && { missingSignals: absentActor.missingSignals }),
+      } as any);
+    });
 
     return {
       ghostNodes,
-      institutionalLogics: result.institutionalLogics,
-      methodologicalNotes: result.methodologicalNotes,
-      dominantDiscourses,
+      dominantDiscourses: dominantDiscoursesFromDoc,
       ...(parsedUserActors.length > 0 && { userActorsUsed: parsedUserActors }),
     };
+
   } catch (error) {
     console.error("[GHOST_NODES] Ghost node detection error:", error);
-    console.error("[GHOST_NODES] Error details:", JSON.stringify(error, null, 2));
-    // Fallback: detect ghost nodes without AI analysis
-    const ghostNodes = detectGhostNodes(nodesArray, undefined, documentType);
-    return { ghostNodes };
+    return { ghostNodes: detectGhostNodes(nodesArray, undefined, documentType) };
   }
 }
-
