# Algorithmic Transparency Guide

## Overview

This document provides complete transparency about how Instant TEA's algorithms work, including scoring formulas, theoretical foundations, and design decisions.

> [!IMPORTANT]
> **Meta-Governance Acknowledgment**: This tool itself is a governing actant. The designers' choices about lenses, prompts, and metrics constitute meta-governance over how AI governance can be problematized. This document makes those choices visible.

---

## Core Principles

### 1. All Scores Are Interpretive, Not Objective

Every metric generated by Instant TEA is:
- **LLM-generated**: Produced by a large language model with its own biases
- **Theoretically situated**: Based on specific critical theory frameworks
- **Tentative**: Meant as provocations for analysis, not authoritative measurements
- **Designer-influenced**: Shaped by the platform creators' theoretical commitments

### 2. Power Is Centralized in Design Decisions

The platform designers exert power through:
- **Lens selection**: Choosing which theoretical frameworks to operationalize
- **Prompt engineering**: Structuring how the LLM can interpret documents
- **Metric definition**: Deciding what to quantify and how
- **Visualization choices**: Determining how power relations are displayed

### 3. Affected Communities Are Objects, Not Governors

Current limitations:
- Communities appear **inside** visualizations, not as governors of the infrastructure
- No external, community-led oversight of the tool's harms or biases
- Responsibility framed as researcher reflexivity, not enforceable obligations
- No redress mechanisms for those harmed by the tool's outputs

---

## Scoring Algorithms

### Epistemic Asymmetry Score

**What it measures**: Imbalance in whose knowledge is recognized as legitimate versus whose is marginalized

**Formula**:
```
EA = (Σ marginalized_knowledge_claims / Σ total_knowledge_claims) × asymmetry_weight
```

**Variables**:
- `marginalized_knowledge_claims`: Number of knowledge claims from non-dominant epistemic positions
- `total_knowledge_claims`: Total number of knowledge claims in the document
- `asymmetry_weight`: Severity multiplier based on structural exclusion patterns (0-1)

**Theoretical Foundation**:
- Framework: Decolonial Theory & Standpoint Epistemology
- Key concepts: Epistemic violence (Spivak), Coloniality of knowledge (Mignolo), Standpoint theory (Harding)
- Citations:
  - Spivak, G. C. (1988). *Can the Subaltern Speak?*
  - Mignolo, W. (2009). *Epistemic Disobedience*
  - Harding, S. (1991). *Whose Science? Whose Knowledge?*

**Design Rationale**:
- **Why this approach**: Quantifying epistemic asymmetry makes invisible power dynamics visible and comparable across documents
- **Alternatives considered**:
  - Binary classification (rejected as too reductive)
  - Qualitative description only (rejected as harder to compare)
  - Citation network analysis (rejected as requiring external data)
- **Known limitations**:
  - Reduces complex epistemic dynamics to a single number
  - May reify categories of 'dominant' vs. 'marginalized' knowledge
  - Depends on LLM's ability to recognize epistemic positions
  - Cannot capture intersectional dimensions

**Caveats**:
- LLM may not recognize all forms of marginalized knowledge
- Score depends on LLM's training data biases
- Cannot capture tacit or embodied knowledge
- Western academic framing may limit recognition of non-Western epistemologies

**Designer Positionality**: Created by researchers positioned in Western academia, attempting to operationalize decolonial critique while acknowledging the contradiction of using AI tools trained on colonial knowledge archives.

---

### Power Concentration Index

**What it measures**: How power is distributed across actors in the assemblage

**Formula**:
```
PCI = 1 - (Σ(pi²) where pi = power share of actor i)
```

**Variables**:
- `pi`: Proportion of total power held by actor i
- `n`: Number of actors in the assemblage

**Theoretical Foundation**:
- Framework: Assemblage Theory & Network Power Analysis
- Key concepts: Assemblage (Deleuze & Guattari), Network centrality (Freeman), Structural power (Strange)
- Citations:
  - Deleuze, G., & Guattari, F. (1987). *A Thousand Plateaus*
  - Freeman, L. C. (1978). *Centrality in social networks*
  - Latour, B. (2005). *Reassembling the Social*

**Design Rationale**:
- **Why this approach**: Adapted from economic concentration indices (Herfindahl-Hirschman) to make power distribution patterns visible
- **Alternatives considered**:
  - Gini coefficient (rejected as less interpretable for power)
  - Simple actor count (rejected as ignoring power differentials)
  - Qualitative categorization (rejected as harder to compare)
- **Known limitations**:
  - Treats power as a quantifiable resource rather than a relation
  - May obscure qualitative differences in types of power
  - Assumes actors are discrete entities (problematic for assemblage theory)
  - Cannot capture potential or latent power

**Caveats**:
- Assumes power can be quantified and aggregated
- May miss informal or invisible power relations
- Depends on LLM's interpretation of 'power'
- Static snapshot - doesn't capture power dynamics over time

**Designer Positionality**: Designed by researchers trained in critical theory but working within quantitative social science traditions, attempting to bridge interpretive and computational approaches.

---

## Overall Design Decisions

### Lens Selection

**Lenses included**: Decolonial, Labor, Accountability, Feminist, Disability Justice

**Why these lenses**:
- Chosen by platform designers based on critical theory traditions
- Reflect designers' commitments to social justice and power critique
- Prioritize marginalized perspectives and structural analysis

**What's excluded**:
- Conservative or market-oriented frameworks
- Techno-solutionist perspectives
- Purely procedural governance approaches

**Implication**: The tool pre-structures what counts as a legitimate governance critique.

### Prompt Engineering

**How prompts work**:
- Templates structure how the LLM can interpret documents
- Pre-defined questions guide the analysis
- Scoring criteria are embedded in prompts

**Power dynamic**:
- Prompt designers determine the interpretive frame
- LLM cannot problematize governance outside these structures
- Users cannot easily modify core prompts (though this could change)

### Visualization Choices

**What we visualize**:
- Network graphs (privilege relational power)
- Heat maps (privilege spatial/intensity dimensions)
- Timeline views (privilege temporal dynamics)

**What we don't visualize**:
- Embodied or affective dimensions of power
- Informal or invisible relations
- Potentiality or latent power

**Implication**: Certain ways of seeing power are privileged over others.

---

## Accountability & Oversight

### Current State

**What exists**:
- ✅ Dual audit trail (technical + interpretive)
- ✅ Mandatory positionality statements
- ✅ Reflexivity prompts
- ✅ This transparency documentation

**What's missing**:
- ❌ External, community-led oversight
- ❌ Redress mechanisms for affected communities
- ❌ Enforceable obligations on tool creators
- ❌ Third-party audits of the tool's own biases
- ❌ Governance board with community representatives

### Responsibility Framework

**Current approach**: Responsibility framed primarily as **researcher reflexivity**
- Users are prompted to reflect on their positionality
- Audit logs track interpretive decisions
- Transparency documentation makes algorithms visible

**Critique**: This places burden on individual users rather than creating enforceable obligations on:
- Platform designers
- LLM vendors
- Institutional deployers

### Future Directions

**Planned improvements**:
1. Community governance board
2. External audit mechanisms
3. Incident reporting system
4. Configurable lens framework
5. Enforceable SLAs with model providers

---

## How to Use This Information

### For Researchers

1. **Read transparency panels** in analysis results
2. **Cite this documentation** when reporting findings
3. **Acknowledge limitations** in your analysis
4. **Reflect on how design choices** shape your interpretations

### For Affected Communities

1. **Understand how you're represented** in the tool's outputs
2. **Report harms or biases** (incident reporting system coming soon)
3. **Demand accountability** from tool creators and deployers
4. **Advocate for governance participation** in tool design

### For Platform Designers

1. **Maintain this documentation** as algorithms evolve
2. **Log all design decisions** with rationale
3. **Conduct regular audits** of tool impacts
4. **Build community oversight mechanisms**

---

## Version History

### Version 1.0 (2026-02-05)
- Initial transparency documentation
- Documented Epistemic Asymmetry Score
- Documented Power Concentration Index
- Acknowledged meta-governance dynamics
- Identified gaps in community oversight

---

## Contact & Feedback

**Report issues**: [Coming soon: Incident reporting system]

**Request features**: [Coming soon: Community governance board]

**Audit requests**: [Coming soon: External audit process]

---

> [!CAUTION]
> **Critical Reminder**: This tool centralizes interpretive agenda-setting in the hands of those who control its design. While we strive for transparency, transparency alone does not redistribute power. Affected communities must become governors of the analytic infrastructure, not just objects within it.
